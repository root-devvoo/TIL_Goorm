# 구름 쿠버네티스 과정 5기 55일차\_20220928

## Kubernetes 정리 (3)

**쿠버네티스 볼륨**

- 데이터의 영구적인 저장
- 파드 내부의 컨테이너 간에 데이터 공유

볼륨의 종류

- 클라우드 서비스<br>(AWS, GCP , AZURE 등에서 제공하는 스토리지 서비스 종류)
- ceph / gluster 등의 스토리지 제품
- NFS / iSCSI 등의 네트워크 스토리지
- configmap / secret 등의 내부 오브젝트
- emptydir / hostpath 등의 간단한 볼륨

1. emptydir
   - 파드 내부의 컨테이너 간에 데이터 공유
   
   - 파드와 라이프사이클이 동일
   
     > 파드가 사라지면, 데이터도 함께 사라짐.
   
   - 컨테이너가 문제 발생 시 재시작해도 볼륨(데이터)은 유지
   
   - 계산이 많이 필요한 어플리케이션
   
   - 초기화 컨테이너로 사전구성 작업 시 사용
   
   - 장점 : 설정에 따라(메모리 지정 시) 연산 성능 향상
   
   - 단점 : 설정에 따라(메모리 지정 시) 데이터 손실(재부팅 시)

> 현재 경로 : `/home/vagrant/volumes`
>
> `vi emptydir_shares` 편집
>
> ```
> apiVersion: apps/v1
> kind: ReplicaSet
> metadata:
> name: kubernetes-emptydir-rs
> spec:
> replicas: 1
> selector:
>  matchLabels:
>    app: webserver
> template:
>  metadata:
>    name: kubernetes-emptydir-pod
>    labels:
>      app: webserver
>  spec:
>    containers:
>       - name: webserver
>         image: nginx:alpine
>         ports:
>         - containerPort: 80
>         volumeMounts:
>         - name: emptydir-vol
>           mountPath: /usr/share/nginx/html
>           readOnly: true
>       - name: contents-creator
>         image: ghcr.io/c1t1d0s7/fortune
>         volumeMounts:
>         - name: emptydir-vol
>           mountPath: /var/htdocs
>       volumes:
>       - name: emptydir-vol
>         emptyDir: {}
> 
> ---
> apiVersion: v1
> kind: Service
> metadata:
>   name: loadbalancer-service
> spec:
>   type: LoadBalancer
>   selector:
>     app: webserver
>   ports:
>   - protocol: TCP
>     port: 80
>     targetPort: 80
> ```
>
> `kubectl apply -f share_emptydir.yaml` 명령어로 적용
>
> ![image](https://user-images.githubusercontent.com/78403443/192672638-34f3bfe1-e335-44b1-bce6-4c39ecd02fef.png)
>
> `vi git.yaml` 편집
>
> ```
> apiVersion: v1
> kind: Pod
> metadata:
>   name: emptydir-git
> spec:
>   initContainers:
>   - name: git-clone
>     image: alpine/git
>     args:
>       - clone
>       - --single-branch
>       - --
>       - https://github.com/kubernetes/kubernetes
>       - /repo
>     volumeMounts:
>     - name: emptydir-vol
>       mountPath: /repo
>   containers:
>   - name: git-repo
>     image: busybox
>     args: ['tail' , '-f' , '/dev/null']
>     volumeMounts:
>     - name: emptydir-vol
>       mountPath: /repo
>   volumes:
>   - name: emptydir-vol
>     emptyDir: {}
> ```
>
> `kubectl apply -f git.yaml` 명령어로 적용
>
> ![image](https://user-images.githubusercontent.com/78403443/192673991-12982fd1-b516-4ebe-be16-04e1ef69c4c8.png)
>
> ![image](https://user-images.githubusercontent.com/78403443/192673656-3726c444-46e1-404f-9ab8-7c19c1539223.png)

2. hostpath
   - 노드(컨테이너가 실행될 시스템)에서 특정 디렉토리를 공유
   - 파드가 종료되더라도 볼륨의 데이터는 유지
   - 멀티노드 환경에서 각 노드마다 해당 파일/디렉토리 존재<br>→ 존재하지 않는 노드에서는 파드가 실행 X
     1. 각 노드가 NFS 등으로 파일/디렉토리를 공유
     2. 파일/디렉토리가 존재하는 노드에서만 파드를 실행<br>→ 노드셀렉터/노드어피니티 를 활용
   - 장점 : 기존의 노드에 있는 파일 공유 가능
   - 단점 : 노드에 대한 제한 (노드마다 데이터가 상이함)

> `vi hostpath.yaml` 편집
>
> ```
> apiVersion: v1
> kind: Pod
> metadata:
>   name: kubernetes-hostpath-pod
> spec:
>   containers:
>   - name: kubernetes-hostpath-pod
>     image: arisu1000/simple-container-app:latest
>     volumeMounts:
>     - mountPath: /hostpath
>       name: hostpath-vol
>     ports:
>     - containerPort: 8080
>   volumes:
>   - name: hostpath-vol
>     hostPath:
>       path: /tmp
>       type: Directory
> ```
>
> ![image](https://user-images.githubusercontent.com/78403443/192674547-599a09e0-38f1-4090-adb0-62505b20a4a3.png)
>
> `kubectl apply -f hostpath.yaml ` 명령어로 적용
>
> ![image](https://user-images.githubusercontent.com/78403443/192675797-9c12bf36-1bee-4a48-9e3e-4140b92040b6.png)
>
> 연결이 되어 파이 id가 똑같은 것을 확인할 수 있다.
>
> ![image](https://user-images.githubusercontent.com/78403443/192676397-f9db0851-d62a-4f44-93c4-d199e762b506.png)

3. nfs

   - 파드에서 사용할 데이터를 영구저장 + 공유
   - NFS서비스를 활용하는 형태
   - nfs서버 구성이 필요 (별도의 시스템 / 파드)
   - 파드 생성 시 볼륨 타입을 nfs 로 설정<br>→ nfs 서버의 IP 주소를 지정

4. PV

   - 파드와 별도로 관리할 수 있는 볼륨

   - kubectl 명령어 관리 가능

   - 파드와는 별개의 라이프사이클

   - hostPath 를 포함해 별도의 스토리지를 활용

   - 정적 / 동적 볼륨 프로비저닝 방식 제공

     정적 프로비저닝<br>→ 직접 PV를 생성<br>PVC 생성 및 연결<br>(크기 등의 요청사항이 일치하는 PV가 있어야 연결)

5. PVC

   - 사용자(개발자)가 스토리지에 대한 지식이 부족해도 PV 사용이 가능하도록 하기 위해 별도로 구성
   - 사용자는 PVC 를 통해 원하는 사이즈 요청<br>→ 관리자(스토리지)가 직접/자동 PV 구성 및 제공
   - 파드에 마운트 설정 시 사용
   - PV 연결을 위해 해당 스토리지를 제공할 SC 이름 설정

6. SC

   - PVC 로 요청 시 동적으로 PV를 생성해주기 위해 필요
   - 스토리지 종류에 따라 각각 다른 형태로 구성
   - 스토리지에 대한 제반지식이 요구

**쿠버네티스 네트워크 구성**

- 쿠버네티스는 파드 하나에 여러 컨테이너 존재

  - pause 컨테이너를 구성<br>→ IP 주소 등을 관리<br>나머지 컨테이너들도 해당 IP 공유

- 멀티 노드 구성

  - 각 노드마다 추가적인 CIDR 구성
  - 노드에 할당하는 파드/서비스 IP 설정
  - 라우팅/NAT 테이블 을 통해 포워딩

- 내부적인 DNS 서비스

  - 각 파드/서비스 에 대한 DNS 주소가 존재

  - core-DNS 를 통해서 서비스 제공<br>→ 혼자서는 부담되기 때문에

    nodelocaldns 를 이용해서 서비스 제공<br>(캐시서버)
