# 구름 쿠버네티스 과정 5기 23일차\_20220810

## 웹 서비스 구축

### Ch07. NFS

NFS(Network File System)

- Sun Micro systems에 의해 개발된 프로토콜로 Unix/Linux 사용자들이 네트워크를 통해 파일을 공유할 수 있는 프로토콜

NFS v3

- 안전한 비동기식 쓰기 지원
- NFS v2에 비해 에러에 대한 처리 능력이 향상됨
- 2GB 이상의 파일에 접근 가능함
- RPC 서비스에 의존함 (rpcbind 필요)
- NFS v3 관련 서비스가 다양해 방화벽 설정이 복잡함

NFSv3 관련 서비스

- nfs
- nfslock
- rpcbind
- rpc.mountd
- rpc.fnsd
- lockd
- rpc.statd
- rpc.rquotad

NFS v4

- rpcbind에 의존하지 않고, 서버 자체가 2049/TCP 포트로 수신 대기함
- 마운트, Lock이 NFS 서비스와 통합됨 
- NFSv3에 비해 성능 및 보안성이 향상됨 
- pNFS(Parallel NFS) 사용 가능함
- 이전 버전 NFS 서버와 하위 호환되어 동작함.

NFSv4 관련 서비스

- rpc.mountd
- nfs-server
- rpc.idmapd

<br>

NFS 공유 옵션

- ro : read-only mount
- rw : read-write mount (default)
- no_root_squash : 원격 root 사용자가 NFS 서버의 로컬 root 처럼 사용되지 않도록 root_squash가 기본값으로 설정되어있으며 해당 보안 설정을 해제하고자 할 때 사용하는 옵션
- sync : 이전 요청 사항이 스토리지에 반영되기 전에 다른 요청을 처리하지 않음.
- sec : 네트워크로 접근하는 파일시스템의 보안 인증 옵션을 지정함.
- sys : 서버 로컬 사용자 인증
- none : 클라이언트가 NFS 서버에 root 사용자로 접근시 nfsnobody 로 UID, GID가 할당될 때 사용
- krb5 : Kerberos 인증 사용
- krb5i : Kerberos 인증 사용 + 데이터 무결성 검증
- krb5p : Kerberos 인증 사용 + 데이터 무결성 검증 + 암호화

@NFS Server

NFS 서버 설치

서버 패키지 설치

- `yum install nfs-utils`

- `vim /etc/exports`

  > `NFS_EXPORT_DIR		접속_허용_대상(MOUNT_OPTION)`

- `mkdir NFS_EXPORT_DIR`

- `exportfs -r`

서비스 재시작

- `systemctl start nfs-server.service`<br>`systemctl enable nfs-server.service`

방화벽 설정

- `firewall-cmd --add-service=nfs`

  > 이렇게 하면 nfs와 관련된 서비스의 포트를 자동으로 열어준다.

- `firewall-cmd --add-service=nfs --permanent`

\* 참고 : NFS 서버 주소 형식

- **NFS_SERVER_HOST:NFS_EXPORT_PATH**

  > `192.168.56.101:/nfs`

@NFS Client

마운트

- `yum install nfs-utils`

- `mkdir MOUNT_POINT`

- `mount -t nfs -o rw SERVER_ADDRESS MOUNT_POINT`

  > 여러가지 같이 지정할 때는 콤마로 구분

> 지금까지 본 내용을 1번 가상 머신에서 진행해보자. (1번이 서버가 될 것임)
>
> `yum install nfs-utils` 명령어로 업그레이드 진행 (이미 설치가 되어있어서 업그레이드가 진행됨.)
>
> `vim /etc/exports` 연다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183791897-1199d169-ab39-45d1-b371-aabd024a115d.png)
>
> 저장 후 종료
>
> 지금은 초기 설정이기 때문에
>
> ![image](https://user-images.githubusercontent.com/78403443/183792204-ad3c5d9a-ab93-4a3f-8499-587190013f89.png)
>
> 상태를 확인 후 start와 부팅 시 자동으로 시작할 수 있게 enable 설정 해줬다.
>
> 다시 상태를 확인하니 exited라고 되어있는데, `/nfs` 라는 디렉토리를 `/etc/exports`에 지정해놓고 디렉토리를 만들지 않았고, 권한 설정을 안해줘서 그런 것 같다.
>
> `mkdir /nfs`<br>`chmod 777 /nfs` 명령어로 디렉토리 생성 및 권한 설정했다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183792708-3df0074f-569e-482a-b6ce-b0ff5962b9a2.png)
>
> 그리고 재시작 해줌.
>
> ![image](https://user-images.githubusercontent.com/78403443/183792345-1547a55d-d56c-4bbe-941d-009a16a7e030.png)
>
> 방화벽 설정과 영구 설정도 했다.
>
> 이제 NFS 서버에 다른 호스트가 접근이 가능할 것이다.
>
> (2번 가상 머신, 2번이 클라이언트임)
>
> `mkdir /mnt/nfs1` 명령어로 마운트 포인트로 사용할 디렉토리 만들어줌.
>
> 그리고, `mount -t nfs -o rw,sync HOST:/ADDR` 이 형식으로 마운트 할건데,<BR>`mount -t nfs -o rw,sync 192.168.56.101:/nfs /mnt/nfs1` 이렇게 지정하면 됨.
>
> ![image](https://user-images.githubusercontent.com/78403443/183793239-f7fa14fd-e359-46f3-b973-ae63e7f25f1d.png)
>
> 에러 없이 마운트 된 것을 확인할 수 있다.
>
> user 사용자로 `/mnt/nfs1` 디렉토리 경로로 들어가서
>
> ![image](https://user-images.githubusercontent.com/78403443/183795356-d85e9854-2d50-47ce-9660-fc8ea0c016b7.png)
>
> 이렇게 파일을 만들어줬다.
>
> > 위 이미지 상에서 user사용자로 탭 하나 더 열어서 만들었어야 하는데... root 사용자로  `user-hostb-1.txt, user-hostb-2.txt` 파일을 만들어서 nfsnobody 소유 사용자와 nfsnobody 소유 그룹으로 파일이 생성되었다. ㅠㅠ
> >
> > 반드시 user 사용자로 만들자.
>
> (1번 가상 머신 ㄱㄱ, 1번은 NFS서버임)
>
> ![image](https://user-images.githubusercontent.com/78403443/183795466-87d418ab-6db5-484b-9ec9-451ac086f65d.png)
>
> 2번 가상 머신에서 만든 파일이 확인된다. 
>
> 그리고, 반대로 여기 1번 가상 머신에서 파일을 생성해보자.
>
> ![image](https://user-images.githubusercontent.com/78403443/183796188-c7c5b940-d766-459e-a93a-1f4ba84d7185.png)
>
> ![image](https://user-images.githubusercontent.com/78403443/183796477-01f04b25-a30c-47e9-b7f3-289ea0fac8a7.png)
>
> 생성 완료
>
> (2번 가상 머신 ㄱㄱ, 2번이 클라이언트임)
>
> ![image](https://user-images.githubusercontent.com/78403443/183796328-16845313-c678-4cc6-a455-081649750eb6.png)
>
> 확인했더니 파일이 확인되고, 파일의 내용을 확인할 수 있다.
>
> > 2번 가상 머신에서 user사용자로 탭 하나 더 열어서 파일을 만들었어야 하는데... root 사용자로 `user-hostb-1.txt, user-hostb-2.txt`파일을 만들어서 nfsnobody 사용자와 그룹으로 파일이 생성되었다. ㅠㅠ
> >
> > 그래서 다시 user 사용자로 해서 해보았다.
> >
> > (2번 가상 머신에서) user 사용자로 파일을 다시 만들었다.
> >
> > ![image](https://user-images.githubusercontent.com/78403443/183798035-35e9f1e7-8c97-4d7a-b7ea-59d93ad66fe6.png)
> >
> > (1번 머신 ㄱㄱ)
> >
> > ![image](https://user-images.githubusercontent.com/78403443/183798112-77cce1b7-265d-4cec-9a48-e97e789ad8d4.png)
> >
> > 1번 머신에서도 확인이 잘 된다.

![image](https://user-images.githubusercontent.com/78403443/183798978-ba29192a-9ac6-4461-b208-d126d7a294ed.png)

> 위 내용 관련 실습
>
> (1번 머신에서.. 1번이 서버임)
>
> `vim /etc/exports` 열기
>
> ![image](https://user-images.githubusercontent.com/78403443/183801194-ee70ec10-a45b-4ea5-b83b-ba282ede7c99.png)
>
> 위와 같이 입력 후 저장
>
> ![image](https://user-images.githubusercontent.com/78403443/183799867-12bd7684-71f3-4e7c-921e-91db063f608d.png)
>
> 위와 같이 디렉토리 생성 및 권한 설정
>
> ![image](https://user-images.githubusercontent.com/78403443/183814719-42e1c95e-de9b-4713-8eb0-32af6dc61775.png)
>
> `exportfs -r`로 갱신해줌.
>
> ![image](https://user-images.githubusercontent.com/78403443/183809287-5483a2f5-15ba-41e3-8934-cf61d66f74b0.png)
>
> (2번 머신... 클라이언트로)
>
> `mkdir /mnt/nfs2`
>
> `mkdir /mnt/nfs3`
>
> `mount -t nfs -o rw,sync 192.168.56.101:/nfs2 /mnt/nfs2`
>
> `mount -t nfs -o rw,sync 192.168.56.101:/nfs3 /mnt/nfs3`
>
> 디렉터리 생성 후 마운트 해줌.
>
> ![image](https://user-images.githubusercontent.com/78403443/183801472-a9a862c5-8dee-4fa1-8126-8ef158337773.png)
>
> > nfs4모드로 서버가 동작하고 있다.
>
> 마운트 된 거 확인
>
> ![image](https://user-images.githubusercontent.com/78403443/183810371-e5e7b589-a917-42b4-a6cb-b079bc0010e6.png)
>
> 이렇게 위와 같이 `/mnt/nfs2`에 파일이 만들어졌다.
>
> `/mnt/nfs3`로 이동
>
> ![image](https://user-images.githubusercontent.com/78403443/183811206-0b207788-3fd6-4d6c-ba77-d0b535a46321.png)
>
> 이렇게 파일을 만들어줬다.
>
> 이 마운트들 해제 후 다시 마운트 해본다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183811857-38d4454e-c2f6-45f4-a592-37fa67578c59.png)
>
> 마운트 해제 해서 위와 같이 하나만 남아있고,
>
> 이 상태에서 서버로 가서 설정해본다.
>
> (서버인 1번 머신으로 ㄱㄱ)
>
> ![image](https://user-images.githubusercontent.com/78403443/183812340-532f8e63-bb49-46dd-91f9-5ad0879f9fca.png)
>
> 우리가 사용하고 있는 주소이기 때문에, 얘만 지금 접속이 된다는게 확인이 안되니까 이것을 다른 ip 대역으로 바꾼다.
>
> `vim /etc/exports` 연다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183812801-9a20faa5-85c6-4f9d-9513-661b504c213d.png)
>
> 이렇게 하면 둘다 접속이 안될 것이다. 저장 후 종료.
>
> ![image](https://user-images.githubusercontent.com/78403443/183814719-42e1c95e-de9b-4713-8eb0-32af6dc61775.png)
>
> 그리고, `exportfs -r` 명령어로 갱신해주면 적용이 되었을 것이다.
>
> (2번 가상 머신에 가서 다시 적용.. 클라이언트)
>
> ![image](https://user-images.githubusercontent.com/78403443/183813622-200d874f-6a28-49c6-b24b-b76906f8a7d2.png)
>
> nfs2, nfs3 둘다 마운트가 안된다.
>
> (다시 1번 ㄱㄱ)
>
> 접속되도록 설정한다.
>
> `vim /etc/exports` 연다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183814614-fe2356af-c9e9-4e33-9242-2b699bbaccb3.png)
>
> 다시 원래대로 돌리고, 저장 후 종료.
>
> `exportfs -r`해서 다시 read하도록 설정하고,
>
> ![image](https://user-images.githubusercontent.com/78403443/183814719-42e1c95e-de9b-4713-8eb0-32af6dc61775.png)
>
> (2번 가상 머신으로 가서)
>
> 마운트 다시 시도
>
> ![image](https://user-images.githubusercontent.com/78403443/183814887-fdd1d3d5-07bc-4e98-a3b5-37c9f1e67c1d.png)
>
> 마운트 되었다. (접속 되었다.)
>
> 그래서, 이렇게 다른 대역으로 지정하는 경우에는 접속이 안된다는 것을 알 수 있었다.
>
> (1번 머신 ㄱㄱ)
>
> ![image](https://user-images.githubusercontent.com/78403443/183815233-443ef406-6342-4cfe-9ae9-a06dd22f398a.png)
>
> 여기서 ip주소를 지정했지만, 도메인 주소 대역으로 지정할 수도 있다.
>
> 예를 들어서, example.com 도메인 아래에 있는 대상에 대해서 허용을 해주고 싶다하는 경우에는
>
> 허용해주는 부분에다가
>
> <img src="https://user-images.githubusercontent.com/78403443/183815164-7394665f-26e8-4de3-8a30-c11cdb376e27.png" alt="image" style="zoom:50%;" />
>
> 이렇게 작성해주면 된다.

> ![image](https://user-images.githubusercontent.com/78403443/183806216-d8529340-fcdc-4492-a0ba-3352d46e160b.png)
>
> 위에 표시한 이 옵션들에 대해서 알아보자.
>
> nfs서버인 1번 머신에서 ` vim /etc/exports`
>
> ![image](https://user-images.githubusercontent.com/78403443/183806644-fb80ff1f-6be7-492b-9d05-6b278acd0be9.png)
>
> 위와 같이 작성 후 저장
>
> (2번 머신 ㄱㄱ)
>
> 기존에 마운트된거 해제한다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183806879-d891eaee-8788-480a-98fd-4ea6701cbe51.png)
>
> (1번 ㄱㄱ)
>
> `systemctl restart nfs-server.service` 명령어로 서버 재시작
>
> (2번 ㄱㄱ)
>
> ![image](https://user-images.githubusercontent.com/78403443/183807865-5f17cd8a-ad6d-42b0-8ef1-aed4d2b2501b.png)
>
> 마운트 함.
>
> ![image](https://user-images.githubusercontent.com/78403443/183808507-f6d4e5d5-f122-44d9-8037-cca9de203000.png)
>
> 자동으로 no_root_squash가 적용된 것을 알 수 있다.
>
> nfs2 마운트
>
> ![image](https://user-images.githubusercontent.com/78403443/183808219-397b163b-0305-44ad-85ed-612539005eea.png)
>
> ![image](https://user-images.githubusercontent.com/78403443/183808394-f93178de-af7e-4e34-87ac-b74ebaf6ecc0.png)
>
> nfs2는 ro(read only)로 설정했기 때문에 파일 생성이 안되는 것을 확인할 수 있다.

> 자동 마운트
>
> autofs는 필요할 때만 마운트하고, 필요하지 않을 때는 네트워크를 끊어서 마운트를 해제한다.

---

### Ch09. iSCSI

iSCSI  

- 네트워크를 통해 Block Storage를 제공하는 프로토콜

Storage 

- 데이터를 저장하는 저장공간을 제공하는 장치 또는 기술

Storage 종류

-  DAS(Direct Attached Storage)

  - Storage와 시스템이 직접 케이블로 연결되는 Storage

- NAS(Network Attached Storage)

  - Storage와 시스템이 네트워크를 통해 연결되는 Storage

    > ![image](https://user-images.githubusercontent.com/78403443/183820630-b2d1c5be-d34b-42cc-a947-520ece568418.png)

- SAN(Storage Area Network)

  - Storage와 시스템이 Storage 전용의 고속 네트워크(FC Switch)로 연결되는 Storage

iSCSI 용어 정리

- 타겟(Target) : Storage 장치를 제공하는 서버
  - TPG(Target Portal Group) : Target Portal Goup으로 ACL, LUN, Portal 등이 있음
  - ACL(Access Contriol List) : Target에 의해 제공되는 스토리에 연결할 수 있는 Initiator를 제한함
  - LUN(Locgical Unit Number) : Initiator에게 제공할 스토리지 장치에 부여된 논리적 이름
  - Portal : 
- 초기자(Initiator) : Target에서 제공하는 Storage 사용
  - Discovery : Initiator가 연결하려는 Target을 검색하는 단계
  - Login : Initiator가 Target과 연결하기 위해 Discovery 이후를 진행하는 단계
- IQN(iSCSI Qualified Name) : Target, Initiator에서 사용하는 이름

iSCSI 구성 단계

@ iSCSI Server에서

(디스크 추가)

> 1번, 2번 머신 둘다 동적할당으로 20기가짜리 3개 만들어줌.

패키지 설치

- `yum install targetcli`

서비스 시작

- `systemctl start target.service`
- `systemctl enable target.service`

타겟 내보내기 설정

- `targetcli`

> - (1) backstore 생성
>
>   `/backstores/block create name=BLOCK_NAME dev=BLOCK_DEVICE_FILE`
>
> - (2) IQN 주소 설정
>
>   ` /iscsi create wwn=TARGET_IQN`
>
>   > ` /iscsi create wwn=iqn.YYYY-MM.REVERSE_DOMAIN_NAME:HOST`
>   >
>   > > `/iscsi create wwn=iqn.2022-08.com.example:hosta`
>
> - (3) ACL 설정
>
>   `/iscsi/iqn.2022-08.com.example:hosta/tpg1/acls create wwn=iqn.2022-08.com.example:hostb`
>
> - (4) LUN 설정
>
> - (5) Portal 설정
>
>   ```bash
>   /> /iscsi/iqn.2022-08.com.example:hosta/tpg1/portals create 192.168.56.101 3260
>     
>    (오류가 발생하는 경우에만 아래 진행 후 위 명령어 진행)
>   /> /iscsi/iqn.2022-08.com.example:hosta/tpg1/portals delete 0.0.0.0 3260
>     
>   ```
>

방화벽 설정

- `firewall-cmd --add-port=3260/tcp`
- `firewall-cmd --add-port=3260/tcp --permanent`

> (1번 가상머신이 서버(Target 서버), 2번 가상머신이 클라이언트(Initiator))
>
> 1번 가상머신에 `yum install targetcli` 명령어로 targetcli 설치함.
>
> ![image](https://user-images.githubusercontent.com/78403443/183828973-b8ee386a-0d30-4908-883b-23b9babcb548.png)
>
> ![image](https://user-images.githubusercontent.com/78403443/183829182-87009b54-4b79-465b-aaae-d3d29edc668a.png)
>
> 시작도 해줌.
>
> targetcli 명령어로 들어간다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183830220-1d5241f6-14cf-4ba1-8540-69946427467f.png)
>
> ![image](https://user-images.githubusercontent.com/78403443/183831448-9e4abd39-b17c-4702-83db-ec7fe8e16d35.png)
>
> `/dev/sdb` 디스크에 대해 해본다.
>
> [(1) backstore 생성]
>
> ![image](https://user-images.githubusercontent.com/78403443/183830601-ce2958d2-20ac-4216-972b-8d0ca2ccf28c.png)
>
> [(2) IQN 주소 설정]
>
> ![image](https://user-images.githubusercontent.com/78403443/183830916-473b28fc-8ec2-4048-857d-e349c35f0e5f.png)
>
> 도메인은 역방향으로 적어준다. 위 경우는 도메인이 example.com 일 경우
>
> [(3) ACL 설정]
>
> ![image](https://user-images.githubusercontent.com/78403443/183831601-4ecd43f8-9329-49d4-a178-9e47095202c9.png)
>
> [(4) LUN 설정]
>
> ![image](https://user-images.githubusercontent.com/78403443/183831801-76c8d666-6da0-4733-9018-d0a99a6480d3.png)
>
> [(5) Portal 설정]
>
> ![image](https://user-images.githubusercontent.com/78403443/183832463-b8902ada-8439-4541-8a81-d7f882338738.png)
>
> `ls`로 위와 같이 확인
>
> ![image](https://user-images.githubusercontent.com/78403443/183833080-207e4367-9aee-433d-aa69-b2b11f1df599.png)
>
> 3260 포트 등록이 안되서 지워주고, 등록했다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183833280-659f16e3-d4a1-4083-b069-49f8f3ea7d37.png)
>
> saveconfig하면 설정한게 저장된다.
>
> (아 오늘 진짜 개 ㅈ같다... D드라이브가 어떻게 수업 중간에 갑자기 인식이 안된다고 날아가냐.. 여기서부터 영상보고 다시 해야됨)
>
> 접속을 하려면 방화벽 허용이 되있어야 접속이 될 것이다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183858954-ccfb6949-3182-458f-87e9-2d5074cf43ff.png)
>
> 이렇게 해주면 방화벽에서 iSCSI가 허용된다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183859114-2fc522d9-5359-4daf-80bd-e5c2eb107775.png)
>
> 최종적인 설정 확인.

@ iSCSi Client (Initiator)

iSCSI Initiator 패키지 설정

- `yum install iscsi-initiator-utils`

iSCSI Initiator IQN 설정

- `ls -l /etc/iscsi/initiatorname.iscsi `

  > 결과
  >
  > `-rw-r--r--. 1 root root 49 Sep 12 2021 /etc/iscsi/initiatorname.iscsi`

- `vim /etc/iscsi/initiatorname.iscsi`

  > `InitiatorName=iqn.2022-08.com.example:hostb`

iSCSI Initiator 서비스 시작

- `systemctl start iscsi.service`
- `systemctl enable iscsi.service`

iSCSI Target Discovery

- `iscsiadm -m discovery -t sendtargets -p TARGET_HOST_IP` 

- `iscsiadm -m discovery -t sendtargets -p 192.168.56.101`

  > `192.168.56.101:3260,1 iqn.2022-08.com.example:hosta`

iSCSI Target Login

- `iscsiadm -m node -T iqn.com.example:hosta -l`
- `iscsiadm -m node -T TARGET_HOST:hosta -l`

(로그인 확인)

```
[root@hostb ~]# ls -l /dev/sd?
brw-rw----. 1 root disk 8,  0 Aug 10 15:08 /dev/sda
brw-rw----. 1 root disk 8, 16 Aug 10 15:08 /dev/sdb
brw-rw----. 1 root disk 8, 32 Aug 10 15:08 /dev/sdc
brw-rw----. 1 root disk 8, 48 Aug 10 15:08 /dev/sdd
brw-rw----. 1 root disk 8, 64 Aug 10 16:33 /dev/sde
```

iSCSI Target Logout (Target과의 연결 해제)

- `iscsiadm -m node -T iqn.2022-08.com.example:hosta -u`

파티셔닝

- `fdisk /dev/sde`

파일시스템 초기화

- `mkfs -t FS_TYPE PARTITON_DEVICE`

마운트 (일회성 마운트, 영구 마운트)

> 일회성 마운트, 영구마운트 둘 중 편한걸로 하면 되겠다.

- `mount -t FS_TYPE -o netdev PARTITION_DEVICE MOUNT_POINT`
- `mount -t ext4 -o _netdev /dev/sde1 /mnt/storage1`

영구 마운트 설정

- `vim /etc/fstab`

  > 아래와 같이 작성함
  >
  > `/dev/sde1		/mnt/storage1		ext4	_netdev		0 0`

영구 마운트 확인

- `mount | grep _netdev`

  > 결과
  >
  > ```
  > /dev/sde1 on /mnt/storage1 type ext4 (rw,relatime,seclabel,stripe=8191,data=ordered,_netdev)
  > ```

> (이번에는 2번 가상머신에서 진행)
>
> `yum install iscsi-initiator-utils -y` 명령어로 설치
>
> > `-y` 옵션을 끝에 붙이면 자동으로 yes해서 설치해준다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183859982-f66c28b1-a765-42d4-9995-fbd853902a8c.png)
>
> inactive니까 시작을 해줘야하는데, 시작하기 전에 설정파일을 설정해줘야한다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183860325-e2bfbac4-228f-4d03-9ecb-cc87a4de28c4.png)
>
> 이 파일을 설정해줘야 한다.
>
> > 이거 설정하면 재시작해줘야하니까 미리 설정하고 시작
>
> > 우리가 아까 설정해준거 보면, tpg1 밑에 acls에서 정의해줬는데, 표시한게 타겟에 대해 접근할 수 있는 대상(Initiator)이다.
> >
> > ![image](https://user-images.githubusercontent.com/78403443/183861667-3812fd87-68d7-4f39-a9e2-ef061ccbb9e1.png)
>
> `vim /etc/iscsi/initiatorname.iscsi` 열자.
>
> ![image](https://user-images.githubusercontent.com/78403443/183862166-e914db92-24a7-4476-b022-a3f32c975b05.png)
>
> 이렇게 작성해주고 저장 후 종료.
>
> [iSCSI Initiator 서비스 시작]
>
> ![image](https://user-images.githubusercontent.com/78403443/183862531-cc062ad6-7718-434f-bd25-de81bfd11bbf.png)
>
> [iSCSI Target Discovery]
>
> > 지금 상태는
> >
> > ![image](https://user-images.githubusercontent.com/78403443/183863918-00ac7a9d-3e23-411b-9686-992471586f38.png)
> >
> > 타겟에 연결된 상태가 아님.<br>타겟에 연결이 되고, 인증을 거쳐 로그인을 하게 되면, 타겟에 있는 저장장치를 가져오게 된다. 그럴 때 변할 것이다.. 그때 다시 확인해보도록 하자.
>
> > `iscsiadm --help` 해서 보면 옵션이 되게 많다.
> >
> > ![image](https://user-images.githubusercontent.com/78403443/183864637-f3606af1-0983-4124-9443-edd500ce3776.png)
> >
> > `-m`은 모드를 지정하는 옵션이다. (discovery mode, node mode, session mode 등)
> >
> > ` man iscsiadm` 해서 보자.
> >
> > ![image](https://user-images.githubusercontent.com/78403443/183864948-3b78f976-5a9c-4c30-aeb4-3ebf8227483f.png)
> >
> > `-p`는 포털을 지정할 때 사용
>
> 여기서 포트를 생략하면 알아서 iscsi 포트인 3260 포트로 지정이 된다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183865534-5c9322de-9aa6-48d3-9e20-3a52cfa119d3.png)
>
> 이걸 참고해서 로그인해서 사용을 하게 되면, 타겟에 있는 디스크를 받아와서 사용할 수가 있다. (아직 연결한거 아니고 검색만 한거임)
>
> 이 상태에서 연결을 하고 싶다면 모드를 별도로 다르게 지정해야한다.
>
> > `-t` 옵션은 타겟 전송모드를 가리키는 것<br>`-T` 옵션은 타겟의 이름을 지정하는 형태로 되어있다.
> >
> > ![image](https://user-images.githubusercontent.com/78403443/183866317-68eaa613-f1dd-44f7-9ae6-520028b9c0af.png)
> >
> > `-l`은 로그인을 하는 옵션이다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183866879-0de912f7-428c-4f0b-b18e-8a13260482f1.png)
>
> 이렇게 있는 상태에서 로그인을 해본다.
>
> [iSCSI Target Login]
>
> ![image](https://user-images.githubusercontent.com/78403443/183867054-f3b7c4c0-53c6-48f2-8b36-dc07a6edc74d.png)
>
> 이렇게 위와 같이 로그인하면 사용이 가능함. (로그인 된 것임)
>
> 로그인 하게 되면,
>
> ![image](https://user-images.githubusercontent.com/78403443/183867539-2989cd48-747b-4fbd-89ef-ee33aba47939.png)
>
> `sde`가 새롭게 만들어진 것을 확인할 수 있다.
>
> 우선은, 연결이 된 상태에서 장치가 있다는 것을 확인해보자.
>
> ![image](https://user-images.githubusercontent.com/78403443/183867924-9350a3cf-ed06-4bbe-8c64-f84c45e7931e.png)
>
> `sde`가 확인된다.
>
> > `lsblk`는 블럭 디바이스의 목록을 보는 명령어다.
>
> (여기에 대해서 로그아웃을 하고 싶다면)
>
> [iSCSI Target Logout (Target과의 연결 해제)]
>
> ![image](https://user-images.githubusercontent.com/78403443/183868294-6320e673-a946-4956-87a7-b2c48562fe1a.png)
>
> 위와 같이, 세션 먼저 확인함.
>
> > ![image](https://user-images.githubusercontent.com/78403443/183869020-bb304fc9-b072-4c1f-8e73-2ffdeb04c5ca.png)
> >
> > 세션을 계층적으로 보고 싶다면 위와 같이 확인할 수 있다.
> >
> > > `-P 3`은 계층적으로 3단계로 보여달라는 의미임
>
> 이제 로그아웃을 해본다.
>
> 로그아웃은 `-u` 를 지정하면 로그아웃된다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183869510-2d0c7f53-c851-4caf-a92d-2e93ba8005f0.png)
>
> 로그아웃이 되어서 `sde` 장치가 보이지 않는 것도 확인할 수 있다.
>
> 다시 한번 연결해본다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183869880-4c1f496a-7219-44bb-a57d-c5af29001bb7.png)
>
> 포트 번호 넣어줘도 마찬가지로 똑같이 연결됨.
>
> ![image](https://user-images.githubusercontent.com/78403443/183870233-700eb6d7-b18d-485c-99b7-a997583e4716.png)
>
> 위와 같이, 로그인 하면 `sde` 장치가 새로 생겨 확인된다.
>
>  ![image](https://user-images.githubusercontent.com/78403443/183870471-da40e361-fb73-4311-b8a3-e6b205a88321.png)
>
> [`sde`를 가지고 fdisk에서 열어보도록 한다]
>
> ![image](https://user-images.githubusercontent.com/78403443/183871005-cf6871a3-c574-404f-8906-9ebd7033371a.png)
>
> `fdisk /dev/sde`로 들어감
>
> ![image](https://user-images.githubusercontent.com/78403443/183871274-021edb29-f38b-4234-897b-738fbbb3a5d7.png)
>
> 위와 같이 만들고 저장
>
> [파일 시스템 초기화]
>
> ![image](https://user-images.githubusercontent.com/78403443/183871410-70d6872b-7dab-4b3e-8416-f48a552c1310.png)
>
> 이렇게 초기화가 되면,<br>`mkdir /mnt/storage1`<br>마운트 포인트를 만들고 마운트 ㄲ
>
> [일회성 마운트, 영구 마운트 둘다 진행해본다]
>
> (일회성 마운트)
>
> ![image](https://user-images.githubusercontent.com/78403443/183873457-65d0573f-8a7f-4055-9517-2523a4cc4334.png)
>
> > `_netdev`는 iSCSI로 마운트할 때, 마운트하는 옵션이다. 꼭 지정해야한다. (디폴트로 지정하면 안된다)
>
> 마운트 해줬고, 디스크 안에 진입이 된 것을 위 이미지와 같이 확인할 수 있다.
>
>  (영구 마운트)
>
> `vim /etc/fstab` 열어서
>
> ![image](https://user-images.githubusercontent.com/78403443/183873986-ea03bec6-10d2-4af2-b192-fd254fb41247.png)
>
> 이렇게 해주면 영구 마운트가 될 것이다.
>
> 마운트 되는지 확인하기 위해 일단 umount 해서 해제해주고, 다시 마운트를 해본다.
>
> ![image](https://user-images.githubusercontent.com/78403443/183874278-53c0a86e-b528-4349-9b35-e2f3068c0aba.png)
>
> 그리고, 위와 같이 확인해보면 iSCSI로 마운트된 대상 하나를 확인할 수 있다.
>
> 이렇게 하면, 마운트해서 사용하는 것까지 할 수 있다.
>
> > 지금은 그냥 전통적인 파티셔닝으로 디스크를 사용해봤는데, LVM을 가지고 구성을 할 수도 있다.
> >
> > iSCSI로 가져온 디스크에 대해서 LVM을 구성해서 사용할 수도 있다.
> >
> > 혹은 타겟을 내보내는 타겟 서버에서 아예 디스크 자체를 LVM으로 만들어서 그 LVM 논리 볼륨 자체를 내보낼 수도 있다.
>
> 재부팅을 하더라도 마운트랑 로그인은 그대로 유지되어있다.
>
> `reboot` 명령어로 재부팅 후 보면..
>
> ![image](https://user-images.githubusercontent.com/78403443/183876363-581cce6b-d16b-4187-b1ae-8f70c3558435.png)
>
> 지금은 타겟에 로그인 되어있어서.. exited 상태.. 어쨌든 active 상태로 실행도 되고 있고,
>
> ![image](https://user-images.githubusercontent.com/78403443/183876470-92309ba5-a808-4fee-a2f0-fae70c24c55a.png)
>
> 장치도 확인되고, 
>
> ![image](https://user-images.githubusercontent.com/78403443/183876616-312ebf7d-f285-4807-85f9-42c306237b0e.png)
>
> 접근도 할 수 있다.
>
> > 일반적으로 네트워크에 연결되어있는 것을 확인하는 것은..
> >
> > ![image](https://user-images.githubusercontent.com/78403443/183875968-194f75ea-faf4-4574-a6bc-09c9b10239fc.png)
> >
> > 이렇게 확인할 수 있다. (4번째 필드가 로컬 주소, 5번째 필드가 외부에서 접속하고 있는 ip주소)

---

### Ch10. Apache Web Server

> ![image](https://user-images.githubusercontent.com/78403443/183855400-51597556-e1a7-4487-8c44-2ad2f2f5f4b2.png)

Web servers

- Apache Web Server
- Nginx
- Microsoft IIS (Windows Server)

패키지 설치

- `yum install httpd`

(필요한 경우) 서버 설정 파일 설정

- `vim /etc/httpd/conf/httpd.conf`

  > 필요한 경우 위 파일을 vi에디터로 편집해줌

서비스 시작

- `systemctl start httpd.service`
- `systemctl enable httpd.service`

방화벽에서 서비스 허용

- `firewall-cmd --add-service=http`
- `firewall-cmd --add-service=http --permanent`
